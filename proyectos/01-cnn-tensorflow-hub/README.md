# ğŸ–¼ï¸ Proyecto: Red Convolucional con TensorFlow Hub

## ğŸ“‹ Objetivo

Crear un clasificador de imÃ¡genes usando una red convolucional preentrenada de TensorFlow Hub y aplicar transfer learning para adaptarla a un dataset personalizado.

## ğŸ¯ Lo que aprenderÃ¡s

- âœ… QuÃ© es una red convolucional (CNN)
- âœ… CÃ³mo funcionan las capas convolucionales
- âœ… Transfer learning (reutilizar modelos preentrenados)
- âœ… TensorFlow Hub y modelos preentrenados
- âœ… Data augmentation (aumento de datos)
- âœ… Fine-tuning de modelos

## ğŸ”§ Requisitos

```bash
pip install tensorflow tensorflow-hub matplotlib numpy pillow
```

## ğŸ“ Estructura del Proyecto

```
01-cnn-tensorflow-hub/
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ 01-conceptos-cnn.md          # TeorÃ­a de CNNs
â”œâ”€â”€ 02-basico-cifar10.py         # Ejemplo bÃ¡sico con CIFAR-10
â”œâ”€â”€ 03-transfer-learning.py      # Transfer learning con TF Hub
â”œâ”€â”€ 04-custom-dataset.py         # Clasificador personalizado
â”œâ”€â”€ datos/                       # Dataset personalizado
â”‚   â”œâ”€â”€ entrenamiento/
â”‚   â””â”€â”€ validacion/
â””â”€â”€ modelos/                     # Modelos guardados
```

## ğŸš€ Pasos del Proyecto

### Paso 1: Entender CNNs (TeorÃ­a)

Lee [`01-conceptos-cnn.md`](./01-conceptos-cnn.md) para entender:
- QuÃ© son las capas convolucionales
- CÃ³mo funcionan los filtros
- Pooling y reducciÃ³n de dimensionalidad
- Arquitecturas famosas (VGG, ResNet, MobileNet)

### Paso 2: Ejemplo BÃ¡sico

Ejecuta [`02-basico-cifar10.py`](./02-basico-cifar10.py):

```bash
python 02-basico-cifar10.py
```

Este script:
- Carga el dataset CIFAR-10 (10 clases de objetos)
- Crea una CNN simple desde cero
- Entrena el modelo
- EvalÃºa la precisiÃ³n

**Tiempo estimado:** 15-20 minutos en CPU

### Paso 3: Transfer Learning

Ejecuta [`03-transfer-learning.py`](./03-transfer-learning.py):

```bash
python 03-transfer-learning.py
```

Este script:
- Carga un modelo preentrenado de TensorFlow Hub (MobileNetV2)
- Congela las capas base
- AÃ±ade capas personalizadas
- Entrena solo las capas nuevas
- Compara con el modelo desde cero

**Tiempo estimado:** 10 minutos en CPU

**Resultado esperado:** >90% de precisiÃ³n (vs ~70% del modelo desde cero)

### Paso 4: Dataset Personalizado

Ejecuta [`04-custom-dataset.py`](./04-custom-dataset.py):

```bash
python 04-custom-dataset.py
```

Este script:
- Te guÃ­a para crear tu propio dataset
- Sugiere categorÃ­as (perros vs gatos, flores, objetos, etc.)
- Aplica data augmentation
- Entrena un clasificador personalizado
- Guarda el modelo para uso futuro

## ğŸ¨ Ideas para Datasets Personalizados

1. **Clasificador de Frutas**: Manzanas, naranjas, plÃ¡tanos
2. **Detector de Emociones**: Feliz, triste, neutral (usando caras)
3. **Clasificador de VehÃ­culos**: Coche, moto, bicicleta
4. **Identificador de Mascotas**: Perro, gato, pÃ¡jaro
5. **Clasificador de Ropa**: Camiseta, pantalÃ³n, zapatos

## ğŸ“Š Conceptos Clave

### Â¿QuÃ© es Transfer Learning?

En lugar de entrenar una CNN desde cero (que requiere millones de imÃ¡genes y dÃ­as de entrenamiento), usamos un modelo ya entrenado en ImageNet (1.4 millones de imÃ¡genes, 1000 clases).

**Ventajas:**
- âœ… Entrena mucho mÃ¡s rÃ¡pido
- âœ… Necesita menos datos
- âœ… Mejor precisiÃ³n con menos recursos

**Proceso:**
```
Modelo Preentrenado (ImageNet)
        â†“
Congelar capas base
        â†“
AÃ±adir capas personalizadas
        â†“
Entrenar solo las nuevas capas
        â†“
(Opcional) Fine-tune todo el modelo
```

### Modelos Disponibles en TensorFlow Hub

| Modelo | TamaÃ±o | PrecisiÃ³n | Velocidad |
|--------|--------|-----------|-----------|
| MobileNetV2 | PequeÃ±o | Alta | âš¡âš¡âš¡ Muy rÃ¡pida |
| ResNet50 | Mediano | Muy alta | âš¡âš¡ RÃ¡pida |
| EfficientNet | Variable | Excelente | âš¡âš¡âš¡ Muy rÃ¡pida |
| InceptionV3 | Grande | Muy alta | âš¡ Media |

**RecomendaciÃ³n para empezar:** MobileNetV2

## ğŸ“ˆ Resultados Esperados

### Modelo desde cero (CNN simple)
- PrecisiÃ³n en CIFAR-10: ~70%
- Tiempo de entrenamiento: 15-20 min (CPU)

### Transfer Learning (MobileNetV2)
- PrecisiÃ³n en CIFAR-10: >90%
- Tiempo de entrenamiento: 5-10 min (CPU)

### Dataset personalizado (100 imÃ¡genes por clase)
- PrecisiÃ³n esperada: 85-95%
- Tiempo de entrenamiento: 5 min (CPU)

## ğŸ› SoluciÃ³n de Problemas

### Error: "Out of Memory"
```python
# Reduce el batch_size
batch_size = 16  # en lugar de 32
```

### Error: "No module named tensorflow"
```bash
pip install --upgrade tensorflow
```

### Entrenamiento muy lento
- Reduce el tamaÃ±o de las imÃ¡genes
- Usa menos epochs
- Considera usar Google Colab (GPU gratis)

## ğŸ“ Siguientes Pasos

DespuÃ©s de completar este proyecto:

1. **Experimenta** con diferentes arquitecturas
2. **Prueba** otros datasets de TensorFlow Datasets
3. **Implementa** data augmentation avanzada
4. **Despliega** tu modelo en una aplicaciÃ³n web
5. **Explora** object detection (YOLO, SSD)

## ğŸ“š Recursos Adicionales

- [TensorFlow Hub](https://tfhub.dev/)
- [TensorFlow Datasets](https://www.tensorflow.org/datasets)
- [Visualizar CNNs](https://poloclub.github.io/cnn-explainer/)

## âœ… Checklist de CompletaciÃ³n

- [ ] EntendÃ­ quÃ© es una CNN y cÃ³mo funciona
- [ ] EjecutÃ© el ejemplo bÃ¡sico con CIFAR-10
- [ ] ProbÃ© transfer learning con TF Hub
- [ ] CreÃ© un dataset personalizado
- [ ] EntrenÃ© un clasificador para mi dataset
- [ ] GuardÃ© y probÃ© el modelo entrenado
- [ ] ExperimentÃ© con diferentes hiperparÃ¡metros

---

**Tiempo total estimado:** 4-6 horas

Â¡Buena suerte! ğŸš€
