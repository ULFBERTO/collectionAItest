"""
CNN con TensorFlow Hub - Transfer Learning
===========================================

Este script demuestra c√≥mo usar modelos preentrenados de TensorFlow Hub
para clasificar im√°genes con muy poco c√≥digo y alta precisi√≥n.
"""

import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduce warnings de TF

import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import cifar10

print("=" * 70)
print("CNN CON TENSORFLOW HUB - TRANSFER LEARNING")
print("=" * 70)

print(f"\n‚úÖ TensorFlow versi√≥n: {tf.__version__}")
print(f"‚úÖ TensorFlow Hub importado correctamente")

# ============================================================================
# 1. CARGAR Y PREPARAR DATOS
# ============================================================================
print("\n1Ô∏è‚É£  CARGANDO DATASET CIFAR-10")
print("-" * 70)

# CIFAR-10: 60,000 im√°genes de 32x32 en 10 clases
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Nombres de las clases
class_names = ['‚úàÔ∏è Avi√≥n', 'üöó Auto', 'üê¶ P√°jaro', 'üê± Gato', 'ü¶å Ciervo',
               'üêï Perro', 'üê∏ Rana', 'üê¥ Caballo', 'üö¢ Barco', 'üöö Cami√≥n']

print(f"Datos de entrenamiento: {x_train.shape}")
print(f"Datos de prueba: {x_test.shape}")
print(f"Clases: {len(class_names)}")

# Normalizar im√°genes a rango [0, 1]
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Tomar un subset para entrenar m√°s r√°pido (opcional)
# Para producci√≥n, usa todo el dataset
QUICK_MODE = True  # Cambia a False para usar todo el dataset

if QUICK_MODE:
    x_train = x_train[:5000]
    y_train = y_train[:5000]
    print(f"\n‚ö° MODO R√ÅPIDO: Usando solo {len(x_train)} im√°genes de entrenamiento")

# ============================================================================
# 2. VISUALIZAR DATOS
# ============================================================================
print("\n2Ô∏è‚É£  VISUALIZACI√ìN DE DATOS")
print("-" * 70)

plt.figure(figsize=(12, 6))
for i in range(20):
    plt.subplot(4, 5, i + 1)
    plt.imshow(x_train[i])
    plt.title(class_names[y_train[i][0]], fontsize=9)
    plt.axis('off')

plt.suptitle('Ejemplos del Dataset CIFAR-10', fontsize=14, y=1.00)
plt.tight_layout()
plt.savefig('d:/EVIROMENT/PracticaIA/proyectos/01-cnn-tensorflow-hub/01-dataset-ejemplos.png', dpi=100, bbox_inches='tight')
print("‚úÖ Guardado: 01-dataset-ejemplos.png")

# ============================================================================
# 3. MODELO 1: CNN SIMPLE DESDE CERO
# ============================================================================
print("\n\n3Ô∏è‚É£  MODELO 1: CNN SIMPLE DESDE CERO")
print("-" * 70)

modelo_simple = models.Sequential([
    # Entrada: 32x32x3
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    
    layers.Conv2D(64, (3, 3), activation='relu'),
    
    # Aplanar y capas densas
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')  # 10 clases
], name='CNN_Simple')

modelo_simple.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(modelo_simple.summary())

print("\n‚è≥ Entrenando modelo simple...")
print("üí° Esto tomar√° unos minutos. ¬°Ten paciencia!")

history_simple = modelo_simple.fit(
    x_train, y_train,
    batch_size=64,
    epochs=10,
    validation_split=0.2,
    verbose=1
)

# Evaluar
test_loss_simple, test_acc_simple = modelo_simple.evaluate(x_test, y_test, verbose=0)
print(f"\n‚úÖ Precisi√≥n en test (CNN simple): {test_acc_simple*100:.2f}%")

# ============================================================================
# 4. MODELO 2: TRANSFER LEARNING CON MOBILENET
# ============================================================================
print("\n\n4Ô∏è‚É£  MODELO 2: TRANSFER LEARNING CON MOBILENETV2")
print("-" * 70)

# MobileNetV2 espera im√°genes de 224x224
# Necesitamos redimensionar nuestras im√°genes
IMAGE_SIZE = 224

def resize_images(images, size=IMAGE_SIZE):
    """Redimensiona im√°genes a 224x224 para MobileNet"""
    return tf.image.resize(images, (size, size)).numpy()

print(f"‚è≥ Redimensionando im√°genes a {IMAGE_SIZE}x{IMAGE_SIZE}...")
x_train_resized = resize_images(x_train)
x_test_resized = resize_images(x_test)
print(f"‚úÖ Forma nueva: {x_train_resized.shape}")

# Cargar MobileNetV2 preentrenado en ImageNet
print("\n‚è≥ Descargando MobileNetV2 desde TensorFlow Hub...")
print("üí° Primera vez puede tomar un minuto. Luego se cachea.")

# URL del modelo en TF Hub
MOBILENET_URL = "https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4"

# Crear modelo con transfer learning
modelo_transfer = models.Sequential([
    # Capa de entrada
    layers.InputLayer(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),
    
    # Modelo preentrenado (congelado)
    hub.KerasLayer(MOBILENET_URL, trainable=False),
    
    # Capas personalizadas
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5),
    layers.Dense(10, activation='softmax')
], name='MobileNet_Transfer')

modelo_transfer.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(modelo_transfer.summary())

print("\n‚è≥ Entrenando modelo con transfer learning...")
print("üí° Ser√° mucho m√°s r√°pido porque solo entrenamos las capas finales")

history_transfer = modelo_transfer.fit(
    x_train_resized, y_train,
    batch_size=32,
    epochs=5,  # Menos epochs porque converge m√°s r√°pido
    validation_split=0.2,
    verbose=1
)

# Evaluar
test_loss_transfer, test_acc_transfer = modelo_transfer.evaluate(
    x_test_resized, y_test, verbose=0
)
print(f"\n‚úÖ Precisi√≥n en test (Transfer Learning): {test_acc_transfer*100:.2f}%")

# ============================================================================
# 5. COMPARACI√ìN DE MODELOS
# ============================================================================
print("\n\n5Ô∏è‚É£  COMPARACI√ìN DE RESULTADOS")
print("-" * 70)

print("\nüìä RESULTADOS FINALES:")
print(f"  CNN Simple:          {test_acc_simple*100:.2f}%")
print(f"  Transfer Learning:   {test_acc_transfer*100:.2f}%")
print(f"  Mejora:              +{(test_acc_transfer - test_acc_simple)*100:.2f}%")

# Visualizaci√≥n de comparaci√≥n
fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Gr√°fico 1: Precisi√≥n del modelo simple
axes[0, 0].plot(history_simple.history['accuracy'], label='Entrenamiento', linewidth=2)
axes[0, 0].plot(history_simple.history['val_accuracy'], label='Validaci√≥n', linewidth=2)
axes[0, 0].set_title('CNN Simple - Precisi√≥n', fontsize=12, fontweight='bold')
axes[0, 0].set_xlabel('√âpoca')
axes[0, 0].set_ylabel('Precisi√≥n')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Gr√°fico 2: P√©rdida del modelo simple
axes[0, 1].plot(history_simple.history['loss'], label='Entrenamiento', linewidth=2)
axes[0, 1].plot(history_simple.history['val_loss'], label='Validaci√≥n', linewidth=2)
axes[0, 1].set_title('CNN Simple - P√©rdida', fontsize=12, fontweight='bold')
axes[0, 1].set_xlabel('√âpoca')
axes[0, 1].set_ylabel('P√©rdida')
axes[0, 1].legend()
axes[0, 1].grid(True, alpha=0.3)

# Gr√°fico 3: Precisi√≥n transfer learning
axes[1, 0].plot(history_transfer.history['accuracy'], label='Entrenamiento', linewidth=2)
axes[1, 0].plot(history_transfer.history['val_accuracy'], label='Validaci√≥n', linewidth=2)
axes[1, 0].set_title('Transfer Learning - Precisi√≥n', fontsize=12, fontweight='bold')
axes[1, 0].set_xlabel('√âpoca')
axes[1, 0].set_ylabel('Precisi√≥n')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Gr√°fico 4: Comparaci√≥n de barras
modelos = ['CNN\nSimple', 'Transfer\nLearning']
precisiones = [test_acc_simple * 100, test_acc_transfer * 100]
colores = ['#3498db', '#2ecc71']

bars = axes[1, 1].bar(modelos, precisiones, color=colores, edgecolor='black', linewidth=2)
axes[1, 1].set_ylabel('Precisi√≥n (%)', fontsize=11)
axes[1, 1].set_title('Comparaci√≥n Final', fontsize=12, fontweight='bold')
axes[1, 1].set_ylim(0, 100)
axes[1, 1].grid(True, alpha=0.3, axis='y')

# A√±adir valores encima de las barras
for bar, val in zip(bars, precisiones):
    height = bar.get_height()
    axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{val:.1f}%', ha='center', va='bottom', 
                    fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig('d:/EVIROMENT/PracticaIA/proyectos/01-cnn-tensorflow-hub/02-comparacion-modelos.png', 
            dpi=100, bbox_inches='tight')
print("\n‚úÖ Guardado: 02-comparacion-modelos.png")

# ============================================================================
# 6. PREDICCIONES DE EJEMPLO
# ============================================================================
print("\n\n6Ô∏è‚É£  PREDICCIONES DE EJEMPLO")
print("-" * 70)

# Seleccionar im√°genes aleatorias
indices = np.random.choice(len(x_test), 12, replace=False)

# Hacer predicciones
predicciones_simple = modelo_simple.predict(x_test[indices], verbose=0)
predicciones_transfer = modelo_transfer.predict(
    resize_images(x_test[indices]), verbose=0
)

# Visualizar
fig, axes = plt.subplots(3, 4, figsize=(14, 10))
axes = axes.flatten()

for i, idx in enumerate(indices):
    # Mostrar imagen
    axes[i].imshow(x_test[idx])
    
    # Predicci√≥n y etiqueta real
    pred_simple = np.argmax(predicciones_simple[i])
    pred_transfer = np.argmax(predicciones_transfer[i])
    real = y_test[idx][0]
    
    # Color: verde si acierta, rojo si falla
    color_simple = 'green' if pred_simple == real else 'red'
    color_transfer = 'blue' if pred_transfer == real else 'red'
    
    # T√≠tulo
    titulo = f"Real: {class_names[real]}\n"
    titulo += f"CNN: {class_names[pred_simple]}\n"
    titulo += f"TL: {class_names[pred_transfer]}"
    
    axes[i].set_title(titulo, fontsize=9)
    axes[i].axis('off')

plt.suptitle('Predicciones: CNN Simple vs Transfer Learning', 
             fontsize=14, fontweight='bold', y=0.98)
plt.tight_layout()
plt.savefig('d:/EVIROMENT/PracticaIA/proyectos/01-cnn-tensorflow-hub/03-predicciones.png', 
            dpi=100, bbox_inches='tight')
print("‚úÖ Guardado: 03-predicciones.png")

# ============================================================================
# 7. GUARDAR MODELO
# ============================================================================
print("\n\n7Ô∏è‚É£  GUARDANDO MODELO")
print("-" * 70)

# Guardar el mejor modelo
modelo_path = 'd:/EVIROMENT/PracticaIA/proyectos/01-cnn-tensorflow-hub/modelo_transfer_learning.h5'
modelo_transfer.save(modelo_path)
print(f"‚úÖ Modelo guardado en: {modelo_path}")

print("\nüí° Para cargar el modelo m√°s tarde:")
print("   modelo = tf.keras.models.load_model(modelo_path, custom_objects={'KerasLayer': hub.KerasLayer})")

# ============================================================================
# 8. RESUMEN Y CONCLUSIONES
# ============================================================================
print("\n\n" + "=" * 70)
print("üéâ ¬°ENTRENAMIENTO COMPLETADO!")
print("=" * 70)

print("\nüìö LO QUE APRENDISTE:")
print("  ‚úÖ Cargar y preparar datasets de im√°genes")
print("  ‚úÖ Crear una CNN desde cero")
print("  ‚úÖ Usar modelos preentrenados con TensorFlow Hub")
print("  ‚úÖ Transfer learning: aprovechar conocimiento existente")
print("  ‚úÖ Comparar diferentes enfoques")
print("  ‚úÖ Guardar y visualizar resultados")

print("\nüîç CONCEPTOS CLAVE:")
print("  ‚Ä¢ Transfer Learning te da mejor precisi√≥n con menos datos y tiempo")
print("  ‚Ä¢ MobileNetV2 ya conoce patrones visuales b√°sicos de ImageNet")
print("  ‚Ä¢ Solo entrenamos las capas finales para nuestras 10 clases")
print("  ‚Ä¢ Resultado: ~30-40% m√°s de precisi√≥n que entrenar desde cero")

print("\nüöÄ PR√ìXIMOS PASOS:")
print("  1. Experimenta con otros modelos de TF Hub")
print("  2. Prueba con tu propio dataset de im√°genes")
print("  3. Ajusta hiperpar√°metros (learning rate, epochs, etc.)")
print("  4. Implementa data augmentation")
print("  5. Fine-tune: descongelar algunas capas del modelo base")

print("\nüìñ RECURSOS:")
print("  ‚Ä¢ TensorFlow Hub: https://tfhub.dev/")
print("  ‚Ä¢ M√°s datasets: https://www.tensorflow.org/datasets")

print("\n" + "=" * 70)

plt.show()
