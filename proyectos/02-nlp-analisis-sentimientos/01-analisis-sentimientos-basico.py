"""
An√°lisis de Sentimientos - NLP B√°sico
======================================

Clasificador de sentimientos usando t√©cnicas tradicionales de ML.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.pipeline import Pipeline
import re
import warnings
warnings.filterwarnings('ignore')

print("=" * 70)
print("AN√ÅLISIS DE SENTIMIENTOS - NLP B√ÅSICO")
print("=" * 70)

# ============================================================================
# 1. DATASET DE EJEMPLO
# ============================================================================
print("\n1Ô∏è‚É£  CREANDO DATASET DE RESE√ëAS")
print("-" * 70)

# Crear dataset de ejemplo (en producci√≥n usar√≠as datos reales)
rese√±as_positivas = [
    "Excelente producto, lo recomiendo totalmente",
    "Me encant√≥, super√≥ mis expectativas",
    "Muy buena calidad, estoy muy satisfecho",
    "Incre√≠ble, es justo lo que necesitaba",
    "Perfecto, lleg√≥ r√°pido y funciona de maravilla",
    "Fant√°stico, vale cada peso que pagu√©",
    "Maravilloso, mi familia est√° encantada",
    "Estupendo, lo volver√≠a a comprar sin dudarlo",
    "Genial, es de muy buena calidad",
    "Extraordinario, supera a productos m√°s caros"
] * 20  # Repetir para tener m√°s datos

rese√±as_negativas = [
    "Muy malo, no sirve para nada",
    "Terrible calidad, una decepci√≥n total",
    "No lo recomiendo, es muy deficiente",
    "Horrible, lleg√≥ roto y no funciona",
    "P√©simo, perd√≠ mi dinero",
    "Muy decepcionante, esperaba mucho m√°s",
    "No vale la pena, busquen otra opci√≥n",
    "Defectuoso, tuve que devolverlo",
    "Mala experiencia, no lo compren",
    "Insatisfecho completamente, no cumple lo prometido"
] * 20

rese√±as_neutrales = [
    "Es un producto normal, nada especial",
    "Cumple su funci√≥n b√°sica",
    "Ni bueno ni malo, es est√°ndar",
    "Para el precio, est√° bien",
    "Es lo que se esperaba",
    "Funciona correctamente",
    "Un producto m√°s del mercado",
    "Aceptable para uso casual",
    "Cumple con lo m√≠nimo",
    "Sin grandes sorpresas"
] * 20

# Combinar y crear DataFrame
textos = rese√±as_positivas + rese√±as_negativas + rese√±as_neutrales
etiquetas = ['positivo'] * len(rese√±as_positivas) + \
            ['negativo'] * len(rese√±as_negativas) + \
            ['neutral'] * len(rese√±as_neutrales)

df = pd.DataFrame({
    'texto': textos,
    'sentimiento': etiquetas
})

# Mezclar datos
df = df.sample(frac=1, random_state=42).reset_index(drop=True)

print(f"Total de rese√±as: {len(df)}")
print(f"\nDistribuci√≥n de sentimientos:")
print(df['sentimiento'].value_counts())

# ============================================================================
# 2. PREPROCESAMIENTO DE TEXTO
# ============================================================================
print("\n\n2Ô∏è‚É£  PREPROCESAMIENTO DE TEXTO")
print("-" * 70)

def limpiar_texto(texto):
    """
    Limpia y normaliza el texto.
    """
    # Convertir a min√∫sculas
    texto = texto.lower()
    
    # Remover caracteres especiales y n√∫meros
    texto = re.sub(r'[^a-z√°√©√≠√≥√∫√±\s]', '', texto)
    
    # Remover espacios extras
    texto = ' '.join(texto.split())
    
    return texto

# Aplicar limpieza
df['texto_limpio'] = df['texto'].apply(limpiar_texto)

print("Ejemplo de limpieza:")
print(f"Original:  {df['texto'].iloc[0]}")
print(f"Limpio:    {df['texto_limpio'].iloc[0]}")

# ============================================================================
# 3. DIVISI√ìN DE DATOS
# ============================================================================
print("\n\n3Ô∏è‚É£  DIVISI√ìN DE DATOS")
print("-" * 70)

X = df['texto_limpio']
y = df['sentimiento']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Conjunto de entrenamiento: {len(X_train)}")
print(f"Conjunto de prueba: {len(X_test)}")

# ============================================================================
# 4. MODELO 1: TF-IDF + LOGISTIC REGRESSION
# ============================================================================
print("\n\n4Ô∏è‚É£  MODELO 1: TF-IDF + REGRESI√ìN LOG√çSTICA")
print("-" * 70)

# Crear pipeline
pipeline_lr = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=1000, ngram_range=(1, 2))),
    ('classifier', LogisticRegression(max_iter=1000, random_state=42))
])

# Entrenar
print("Entrenando...")
pipeline_lr.fit(X_train, y_train)

# Predecir
y_pred_lr = pipeline_lr.predict(X_test)
accuracy_lr = accuracy_score(y_test, y_pred_lr)

print(f"\n‚úÖ Precisi√≥n: {accuracy_lr*100:.2f}%")
print("\nReporte de clasificaci√≥n:")
print(classification_report(y_test, y_pred_lr))

# ============================================================================
# 5. MODELO 2: BAG OF WORDS + NAIVE BAYES
# ============================================================================
print("\n\n5Ô∏è‚É£  MODELO 2: BAG OF WORDS + NAIVE BAYES")
print("-" * 70)

pipeline_nb = Pipeline([
    ('vectorizer', CountVectorizer(max_features=1000, ngram_range=(1, 2))),
    ('classifier', MultinomialNB())
])

print("Entrenando...")
pipeline_nb.fit(X_train, y_train)

y_pred_nb = pipeline_nb.predict(X_test)
accuracy_nb = accuracy_score(y_test, y_pred_nb)

print(f"\n‚úÖ Precisi√≥n: {accuracy_nb*100:.2f}%")

# ============================================================================
# 6. MODELO 3: TF-IDF + SVM
# ============================================================================
print("\n\n6Ô∏è‚É£  MODELO 3: TF-IDF + SVM")
print("-" * 70)

pipeline_svm = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=1000, ngram_range=(1, 2))),
    ('classifier', LinearSVC(random_state=42))
])

print("Entrenando...")
pipeline_svm.fit(X_train, y_train)

y_pred_svm = pipeline_svm.predict(X_test)
accuracy_svm = accuracy_score(y_test, y_pred_svm)

print(f"\n‚úÖ Precisi√≥n: {accuracy_svm*100:.2f}%")

# ============================================================================
# 7. COMPARACI√ìN DE MODELOS
# ============================================================================
print("\n\n7Ô∏è‚É£  COMPARACI√ìN DE MODELOS")
print("-" * 70)

resultados = pd.DataFrame({
    'Modelo': ['Logistic Regression', 'Naive Bayes', 'SVM'],
    'Precisi√≥n': [accuracy_lr, accuracy_nb, accuracy_svm]
})

print(resultados.to_string(index=False))

# Visualizaci√≥n
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Gr√°fico de barras
axes[0].barh(resultados['Modelo'], resultados['Precisi√≥n']*100, 
             color=['#3498db', '#e74c3c', '#2ecc71'], edgecolor='black', linewidth=2)
axes[0].set_xlabel('Precisi√≥n (%)', fontsize=11)
axes[0].set_title('Comparaci√≥n de Modelos', fontsize=12, fontweight='bold')
axes[0].set_xlim(0, 100)
axes[0].grid(True, alpha=0.3, axis='x')

for i, (modelo, prec) in enumerate(zip(resultados['Modelo'], resultados['Precisi√≥n'])):
    axes[0].text(prec*100 + 1, i, f'{prec*100:.1f}%', 
                 va='center', fontsize=10, fontweight='bold')

# Matriz de confusi√≥n del mejor modelo
mejor_modelo_idx = resultados['Precisi√≥n'].idxmax()
mejor_modelo_nombre = resultados.loc[mejor_modelo_idx, 'Modelo']

if mejor_modelo_idx == 0:
    y_pred_mejor = y_pred_lr
elif mejor_modelo_idx == 1:
    y_pred_mejor = y_pred_nb
else:
    y_pred_mejor = y_pred_svm

cm = confusion_matrix(y_test, y_pred_mejor)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=pipeline_lr.classes_,
            yticklabels=pipeline_lr.classes_,
            ax=axes[1])
axes[1].set_title(f'Matriz de Confusi√≥n - {mejor_modelo_nombre}', 
                  fontsize=12, fontweight='bold')
axes[1].set_ylabel('Real', fontsize=11)
axes[1].set_xlabel('Predicci√≥n', fontsize=11)

plt.tight_layout()
plt.savefig('d:/EVIROMENT/PracticaIA/proyectos/02-nlp-analisis-sentimientos/01-comparacion-modelos.png', 
            dpi=100, bbox_inches='tight')
print("\n‚úÖ Guardado: 01-comparacion-modelos.png")

# ============================================================================
# 8. AN√ÅLISIS DE PALABRAS IMPORTANTES
# ============================================================================
print("\n\n8Ô∏è‚É£  PALABRAS M√ÅS IMPORTANTES")
print("-" * 70)

# Obtener vocabulario y coeficientes
vectorizer = pipeline_lr.named_steps['tfidf']
classifier = pipeline_lr.named_steps['classifier']

feature_names = vectorizer.get_feature_names_out()

# Para clasificaci√≥n multiclase, obtenemos coeficientes por clase
for i, clase in enumerate(classifier.classes_):
    coef = classifier.coef_[i]
    top_indices = np.argsort(coef)[-10:][::-1]
    
    print(f"\nPalabras m√°s importantes para '{clase}':")
    for idx in top_indices:
        print(f"  ‚Ä¢ {feature_names[idx]}: {coef[idx]:.3f}")

# ============================================================================
# 9. PREDICCIONES DE EJEMPLO
# ============================================================================
print("\n\n9Ô∏è‚É£  PREDICCIONES DE EJEMPLO")
print("-" * 70)

nuevos_textos = [
    "Este producto es incre√≠ble, me encant√≥ todo",
    "Horrible, el peor producto que he comprado",
    "Es un producto normal, nada del otro mundo",
    "Excelente calidad, muy recomendado",
    "No funciona bien, estoy decepcionado"
]

print("\nProbando el mejor modelo:\n")
for texto in nuevos_textos:
    prediccion = pipeline_lr.predict([texto])[0]
    probabilidades = pipeline_lr.predict_proba([texto])[0]
    
    print(f"Texto: \"{texto}\"")
    print(f"‚Üí Sentimiento: {prediccion.upper()}")
    print(f"  Probabilidades: ", end="")
    for clase, prob in zip(pipeline_lr.classes_, probabilidades):
        print(f"{clase}={prob:.2f} ", end="")
    print("\n")

# ============================================================================
# 10. RESUMEN
# ============================================================================
print("\n" + "=" * 70)
print("üéâ ¬°AN√ÅLISIS COMPLETADO!")
print("=" * 70)

print("\nüìö LO QUE APRENDISTE:")
print("  ‚úÖ Preprocesamiento de texto")
print("  ‚úÖ Vectorizaci√≥n con TF-IDF y Bag of Words")
print("  ‚úÖ Entrenamiento de clasificadores de texto")
print("  ‚úÖ Evaluaci√≥n de modelos NLP")
print("  ‚úÖ Interpretaci√≥n de caracter√≠sticas importantes")

print("\nüîç CONCEPTOS CLAVE:")
print("  ‚Ä¢ TF-IDF: Mide importancia de palabras en documentos")
print("  ‚Ä¢ N-grams: Combinaciones de palabras (ej: 'muy bueno')")
print("  ‚Ä¢ Pipeline: Encadena preprocesamiento y modelo")
print("  ‚Ä¢ Logistic Regression: Excelente para clasificaci√≥n de texto")

print("\nüöÄ PR√ìXIMOS PASOS:")
print("  1. Probar con un dataset real m√°s grande")
print("  2. Implementar embeddings (Word2Vec, GloVe)")
print("  3. Usar redes neuronales (LSTMs)")
print("  4. Agregar more preprocessing (stemming, lemmatization)")
print("  5. Probar con transformers (BERT)")

print("\n" + "=" * 70)

plt.show()
