# ğŸ’¬ Proyecto: AnÃ¡lisis de Sentimientos (NLP BÃ¡sico)

## ğŸ“‹ Objetivo

Crear un clasificador de sentimientos que determine si un texto es positivo, negativo o neutral usando tÃ©cnicas de NLP y Machine Learning.

## ğŸ¯ Lo que aprenderÃ¡s

- âœ… Preprocesamiento de texto
- âœ… TokenizaciÃ³n y vectorizaciÃ³n
- âœ… TF-IDF y Bag of Words
- âœ… Word embeddings bÃ¡sicos
- âœ… ClasificaciÃ³n de texto
- âœ… EvaluaciÃ³n de modelos NLP

## ğŸ”§ Requisitos

```bash
pip install numpy pandas scikit-learn nltk matplotlib seaborn wordcloud
```

## ğŸ“ Archivos del Proyecto

- `01-analisis-sentimientos-basico.py` - Clasificador con scikit-learn
- `02-analisis-sentimientos-deep.py` - Red neuronal con embeddings
- `README.md` - Esta guÃ­a

## ğŸš€ EjecuciÃ³n RÃ¡pida

```bash
# Ejemplo bÃ¡sico con ML tradicional
python 01-analisis-sentimientos-basico.py

# Ejemplo avanzado con Deep Learning
python 02-analisis-sentimientos-deep.py
```

## ğŸ“Š Dataset

Usaremos reseÃ±as de productos/pelÃ­culas:
- **Positivas**: "Â¡Excelente producto! Lo recomiendo"
- **Negativas**: "Muy malo, no funciona"
- **Neutrales**: "Es un producto normal"

## ğŸ“ Conceptos Clave

### 1. TokenizaciÃ³n
Dividir texto en palabras/tokens:
```
"Me encanta este producto" â†’ ["Me", "encanta", "este", "producto"]
```

### 2. VectorizaciÃ³n
Convertir texto en nÃºmeros:
- **Bag of Words**: Frecuencia de palabras
- **TF-IDF**: Importancia relativa de palabras

### 3. Embeddings
Representar palabras como vectores densos que capturan significado semÃ¡ntico.

## ğŸ“ˆ Resultados Esperados

- **Modelo bÃ¡sico (TF-IDF + Logistic Regression)**: ~75-85% precisiÃ³n
- **Modelo deep (Embeddings + LSTM)**: ~85-92% precisiÃ³n

---

**Tiempo estimado:** 2-3 horas
